from PyQt6.QtWidgets import QWidget, QSizePolicy, QTableView
from PyQt6.QtCore import pyqtSlot, pyqtSignal
from vspreview.core import Frame, PushButton, VBoxLayout, HBoxLayout, SpinBox, ProgressBar, LineEdit, CheckBox
from vspreview.core.custom import ComboBox, TableModel
from vspreview.plugins import MappedNodesPlugin, PluginConfig, PluginGraphicsView
from vstools import vs

import math
import os
import cv2
import numpy as np
import threading
from PIL import Image

import local

np.set_printoptions(suppress=True)

core = vs.core

__all__ = ["UndermixPlugin"]

renderer = {
    "median": local.bilinear_median_bucket,
    "mean": local.bilinear_mean_bucket,
}

stitchmodes = [
    "Local features affine",
    "Local ECC translation",
    "Global features stitcher",
]

# feature matching
index_params = dict(
    algorithm=6,
    table_number=6,  # 12
    key_size=12,  # 20
    multi_probe_level=1)
search_params = dict(checks=50)
flann = cv2.FlannBasedMatcher(index_params, search_params)

number_of_iterations = 400
termination_eps = 1e-6
criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,
            number_of_iterations, termination_eps)


def feature_matching(cache, i1, i2):
  kp1, des1 = cache[i1]
  kp2, des2 = cache[i2]

  matches2to1 = flann.knnMatch(des2, des1, k=2)
  recip_matches = flann.knnMatch(des1, des2, k=2)

  matchesMask_ratio = [[0, 0] for i in range(len(matches2to1))]
  match_dict = {}
  for i, d in enumerate(matches2to1):
    if len(d) < 2: continue
    m, n = d

    if m.distance < 0.7 * n.distance:
      matchesMask_ratio[i] = [1, 0]
      match_dict[m.trainIdx] = m.queryIdx

  good = []
  matchesMask_ratio_recip = [[0, 0] for i in range(len(recip_matches))]

  for i, d in enumerate(recip_matches):
    if len(d) < 2: continue
    m, n = d
    if m.distance < 0.7 * n.distance:  # ratio
      if m.queryIdx in match_dict and match_dict[
          m.queryIdx] == m.trainIdx:  #reciprocal
        good.append(m)
        matchesMask_ratio_recip[i] = [1, 0]

  return ([kp1[m.queryIdx].pt
           for m in good], [kp2[m.trainIdx].pt for m in good])


class UndermixPlugin(MappedNodesPlugin, QWidget):
  _config = PluginConfig("moe.grass", "Undermix")

  progress_signal = pyqtSignal(int, int, str, bool)

  def setup_ui(self) -> None:
    self.view = PluginGraphicsView(self)

    self.start_n = SpinBox(minimum=0, maximum=100000)
    start_set = PushButton("Set", self, clicked=self.set_start)
    self.end_n = SpinBox(minimum=0, maximum=100000)
    end_set = PushButton("Set", self, clicked=self.set_end)

    self.start_n.setValue(0)
    self.end_n.setValue(100000)

    self.chk_align_inv = CheckBox("Invert", checked=False)

    self.cmb_align_mode = ComboBox()
    self.cmb_align_mode.addItems(stitchmodes)
    self.cmb_align_mode.setCurrentIndex(0)

    btn_align = PushButton("Align", self, clicked=self.analyze)
    btn_align.setSizePolicy(QSizePolicy.Policy.Maximum,
                            QSizePolicy.Policy.Maximum)

    self.chk_align_mask = CheckBox("Align mask", checked=False)
    self.txt_align_mask = LineEdit("alignmask.png")
    self.txt_align_mask.setSizePolicy(QSizePolicy.Policy.Preferred,
                                      QSizePolicy.Policy.Maximum)

    self.chk_align_mask_inv = CheckBox("Invert", checked=False)

    self.chk_render_mask = CheckBox("Render mask", checked=False)
    self.txt_render_mask = LineEdit("rendermask.png")
    self.txt_render_mask.setSizePolicy(QSizePolicy.Policy.Preferred,
                                       QSizePolicy.Policy.Maximum)

    self.chk_render_mask_inv = CheckBox("Invert", checked=False)

    self.outpath = LineEdit("stitched.png")
    self.outpath.setSizePolicy(QSizePolicy.Policy.Preferred,
                               QSizePolicy.Policy.Maximum)

    self.rendermode = ComboBox()
    self.rendermode.addItems(renderer.keys())
    self.rendermode.setCurrentIndex(0)
    btn_render = PushButton("Render", self, clicked=self.render)
    btn_render.setSizePolicy(QSizePolicy.Policy.Maximum,
                             QSizePolicy.Policy.Maximum)

    self.progress = ProgressBar()
    self.progress.setTextVisible(True)

    self.progress_signal.connect(self.update_progress)

    self.table_offsets = QTableView(None)
    self.table_offsets.setModel(TableModel([], ["x", "y"], True))
    self.table_offsets.setSizePolicy(QSizePolicy.Policy.Minimum,
                                     QSizePolicy.Policy.Preferred)

    rows = [
        [self.start_n, start_set, self.end_n, end_set, self.chk_align_inv],
        [self.chk_align_mask, self.txt_align_mask, self.chk_align_mask_inv],
        [self.chk_render_mask, self.txt_render_mask, self.chk_render_mask_inv],
        [self.cmb_align_mode, btn_align],
        [self.outpath, self.rendermode, btn_render],
    ]
    rows = [HBoxLayout(None, row) for row in rows]

    left = VBoxLayout(None, [self.table_offsets] + rows)
    main = HBoxLayout(None, [left, self.view])
    VBoxLayout(self, [main, self.progress])

    self.align_start = None
    self.align_end = None
    self.align_output = None
    self.align_invert = False
    self.align_mask = False
    self.align_mask_invert = False
    self.features = {}
    self.transforms = {}
    self.offsets_xy = {}
    self.width = None
    self.height = None

  def set_start(self):
    self.start_n.setValue(self.main.current_output.last_showed_frame)

  def set_end(self):
    self.end_n.setValue(self.main.current_output.last_showed_frame)

  def render(self):
    start = self.start_n.value()
    end = self.end_n.value()

    while self.changed():
      self.analyze()

    node = self.main.current_output.prepared.original_clip
    node = core.resize.Point(node, format=vs.RGB24)

    rendermode = self.rendermode.currentIndex()
    total = end - start
    output_filename = self.outpath.text() or "stitched.png"

    rotated_images = {}

    self.progress_signal.emit(0, total, "Rotating frames", False)

    for i in range(start, end + 1):
      (warp_matrix, size) = self.transforms[i]
      frame = node.get_frame(i)

      im = np.ctypeslib.as_array(frame).swapaxes(0, 2).swapaxes(0, 1)

      im = im.reshape((node.height, node.width, 3))
      im = cv2.cvtColor(im, cv2.COLOR_RGB2RGBA)

      mask_im = np.ones(im.shape[:2], dtype=np.uint8)
      mask_im[:] = 255

      feather_im = np.ones(im.shape[:2], dtype=np.float64)

      xd = feather_im.shape[0] // 8
      yd = feather_im.shape[1] // 8

      for x in range(xd):
        feather_im[x, :] = x / xd
        feather_im[-x, :] = x / xd

      for y in range(yd):
        feather_im[:, y] *= y / yd
        feather_im[:, -y] *= y / yd

      im = cv2.warpAffine(im,
                          warp_matrix,
                          size,
                          flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP,
                          borderMode=cv2.BORDER_REPLICATE).astype(np.float64)

      mask = cv2.warpAffine(mask_im,
                            warp_matrix,
                            size,
                            flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP,
                            borderMode=cv2.BORDER_CONSTANT,
                            borderValue=0).astype(np.float64)

      feather_im = cv2.warpAffine(feather_im,
                                  warp_matrix,
                                  size,
                                  flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP,
                                  borderMode=cv2.BORDER_CONSTANT,
                                  borderValue=0).astype(np.float64)

      im[:, :, 3] = mask
      im = np.dstack([im, feather_im])
      rotated_images[i] = im

      self.progress_signal.emit(i - start, total, "Rotating frames", False)

    offsets_xy = [self.offsets_xy[k] for k in rotated_images]
    rotated_images = list(rotated_images.values())

    if self.chk_align_inv.isChecked():
      rotated_images.reverse()
      offsets_xy.reverse()

    offsets_xy = np.array(offsets_xy, dtype=np.float64)

    self.progress_signal.emit(0, self.height, "Rendering", False)

    def render(rendermode, rotated_images, offsets_xy, width, height, path):
      im = list(renderer.values())[rendermode](
          rotated_images, offsets_xy,
          width, height, lambda c: self.progress_signal.emit(
              c + 1, height, "Rendering", False))
      path2 = path
      n = 1
      while os.path.exists(path2):
        a, b = os.path.splitext(path)
        path2 = f"{a}{n}{b}"
        n += 1

      self.progress_signal.emit(height, height, "Saving", False)
      Image.fromarray(im.astype(np.uint8)).save(path2)
      self.progress_signal.emit(height, height, f"Saved as {path2}", True)

    t = threading.Thread(target=render,
                         args=[
                             rendermode, rotated_images, offsets_xy,
                             self.width, self.height, output_filename
                         ],
                         daemon=True)

    t.start()

  @pyqtSlot(int, int, str, bool)
  def update_progress(self, c, total, text, r):
    self.progress.setValue(c)
    self.progress.setMaximum(total)
    if r:
      self.progress.setFormat(text)
    else:
      self.progress.setFormat(f"{text}: {c}/{total}")

  def get_mask(self, mask, n):
    if mask is None or n not in self.transforms: return None

    warp_matrix = self.transforms[n][0]

    warp_matrix = np.vstack([warp_matrix, [0, 0, 1]])
    warp_matrix = np.linalg.inv(warp_matrix)[:2]

    warp_matrix = np.vstack([warp_matrix, [0, 0, 1]])
    trans = np.eye(3, dtype=np.float64)
    trans[0, 2] = self.offsets_xy[n][0]
    trans[1, 2] = self.offsets_xy[n][1]
    warp_matrix = warp_matrix.dot(trans)[:2]

    return cv2.warpAffine(mask,
                          warp_matrix, (1920, 1080),
                          flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP,
                          borderMode=cv2.BORDER_CONSTANT).astype(np.uint8)

  def get_features(self, f, n, mask=None):
    if n in self.features:
      return self.features[n]
    orb = cv2.ORB_create(1000)
    gray = np.ctypeslib.as_array(f).reshape((1080, 1920))
    self.features[n] = orb.detectAndCompute(gray, mask)
    return self.features[n]

  def path_alignmask(self):
    return self.txt_align_mask.text() or "alignmask.png"

  def have_alignmask(self):
    if not self.chk_align_mask.isChecked():
      return False

    if not os.path.exists(self.path_alignmask()):
      print("can't find", self.path_alignmask())
      return False

    return True

  def get_alignmask(self, inv):
    if not self.have_alignmask(): return None

    alignmask = Image.open(self.path_alignmask())
    alignmask = alignmask.convert(mode="L")
    alignmask = np.array(alignmask).astype(np.uint8)

    if inv: alignmask = 255 - alignmask

    return alignmask

  def get_node(self, node):
    if node.format.id == vs.GRAY32: return node

    if self.width == None: return node

    alignmask = self.get_alignmask(self.align_mask_invert)

    def points(n, f):
      im = np.ctypeslib.asarray(f[0]).swapaxes(0, 2).swapaxes(0, 1)

      kp, des = self.get_features(f[1], n, alignmask)
      im = cv2.drawKeypoints(im, kp, None, color=(255, 0, 0), flags=0)

      f = f[0].copy()
      np.copyto(np.asarray(f[0]), im[:, :, 0])
      np.copyto(np.asarray(f[1]), im[:, :, 1])
      np.copyto(np.asarray(f[2]), im[:, :, 2])
      return f

    node = core.resize.Bicubic(node, format=vs.RGB24, matrix_in_s="709")

    if self.width == None and self.cmb_align_mode.currentIndex() == 0:
      gray = core.resize.Bicubic(node, format=vs.GRAY8, matrix_s="709")
      gray = core.std.RemoveFrameProps(gray, "_Matrix")
      gray = core.std.Sobel(gray)

      node = core.std.ModifyFrame(clips=[node, gray],
                                  clip=node,
                                  selector=points)
      return node

    resized = core.resize.Bicubic(node, width=self.width, height=self.height)

    def rotate(n, f):
      if n not in self.transforms or n not in self.offsets_xy:
        return f[1]

      im = np.ctypeslib.asarray(f[0]).swapaxes(0, 2).swapaxes(0, 1)

      if self.cmb_align_mode.currentIndex() == 0 and n in self.features:
        kp, _ = self.features[n]
        im = cv2.drawKeypoints(im, kp, None, color=(255, 0, 0), flags=0)

      (warp_matrix, size) = self.transforms[n]

      im = cv2.warpAffine(im,
                          warp_matrix,
                          size,
                          flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP,
                          borderMode=cv2.BORDER_CONSTANT).astype(np.uint8)

      im2 = np.zeros((f[1].height, f[1].width, 3), np.uint8)

      x, y = self.offsets_xy[n]

      x = int(round(x))
      y = int(round(y))
      x2 = x + im.shape[1]
      y2 = y + im.shape[0]

      x = max(x, 0)
      y = max(y, 0)
      x2 = min(x2, f[1].width)
      y2 = min(y2, f[1].height)

      im2[y:y2, x:x2] = im[:y2 - y, :x2 - x]

      f = f[1].copy()
      np.copyto(np.asarray(f[0]), im2[:, :, 0])
      np.copyto(np.asarray(f[1]), im2[:, :, 1])
      np.copyto(np.asarray(f[2]), im2[:, :, 2])
      return f

    resized = core.std.BlankClip(resized)
    node = core.std.ModifyFrame(clips=[node, resized],
                                clip=resized,
                                selector=rotate)

    if not self.align_mask: return node

    def withmask(n, f):
      im = np.ctypeslib.asarray(f[1]).swapaxes(0, 2).swapaxes(0, 1)
      im0 = np.ctypeslib.asarray(f[0]).swapaxes(0, 2).swapaxes(0, 1)
      im[0:im0.shape[0], 0:im0.shape[1], :] = im0

      mask = self.get_mask(alignmask, n)
      if mask is not None:
        im[0:1080, im0.shape[1]:im0.shape[1] + 1920, 0] = mask
        im[0:1080, im0.shape[1]:im0.shape[1] + 1920, 1] = mask
        im[0:1080, im0.shape[1]:im0.shape[1] + 1920, 2] = mask

        f = f[1].copy()
        np.copyto(np.asarray(f[0]), im[:, :, 0])
        np.copyto(np.asarray(f[1]), im[:, :, 1])
        np.copyto(np.asarray(f[2]), im[:, :, 2])
        return f

      return f[1]

    resized = core.std.BlankClip(resized, width=int(resized.width * 2))

    node = core.std.ModifyFrame(clips=[node, resized],
                                clip=resized,
                                selector=withmask)

    return node

  def changed(self):
    if self.align_start != self.start_n.value(): return True
    if self.align_end != self.end_n.value(): return True

    if self.align_invert != self.chk_align_inv.isChecked(): return True

    if self.have_alignmask():
      if not self.align_mask: return True
      if self.align_mask_invert != self.chk_align_mask_inv.isChecked():
        return True
    else:
      if self.align_mask: return True

    # TODO: align_output

    return False

  def analyze(self):
    if not self.changed(): return

    self.features.clear()
    node = self.main.current_output.prepared.original_clip

    gray = core.resize.Bicubic(node, format=vs.GRAY8, matrix_s="709")
    gray = core.std.RemoveFrameProps(gray, "_Matrix")
    gray = core.std.Sobel(gray)

    features = {}
    warp_matrices = {}
    offsets = {}

    start = self.start_n.value()
    end = self.end_n.value()
    total = end - start

    if end <= start: return

    alignmask = None
    alignmask_invert = self.chk_align_mask_inv.isChecked()
    if self.align_start == start and self.align_end == end and not self.align_mask:
      alignmask = self.get_alignmask(alignmask_invert)

    def get_transform(i1, i2):
      if self.cmb_align_mode.currentIndex() == 1:
        im1 = np.ctypeslib.as_array(gray.get_frame(i1)).reshape((1080, 1920))
        im2 = np.ctypeslib.as_array(gray.get_frame(i2)).reshape((1080, 1920))
        (cc, M) = cv2.findTransformECC(im1, im2, np.eye(2, 3,
                                                        dtype=np.float32),
                                       cv2.MOTION_TRANSLATION, criteria, None)
        # TODO: alignmask
        return M

      mask1 = self.get_mask(alignmask, i1)
      mask2 = self.get_mask(alignmask, i2)

      if mask1 is not None and mask2 is not None:
        self.align_mask = True
      else:
        mask1 = None
        mask2 = None
        self.align_mask = False

      self.get_features(gray.get_frame(i1), i1, mask1)
      self.get_features(gray.get_frame(i2), i2, mask2)

      pts1, pts2 = feature_matching(self.features, i1, i2)

      src_pts = np.float32(pts1).reshape(-1, 1, 2)
      dst_pts = np.float32(pts2).reshape(-1, 1, 2)

      M, mask = cv2.estimateAffinePartial2D(src_pts,
                                            dst_pts,
                                            cv2.USAC_MAGSAC,
                                            ransacReprojThreshold=5.0)

      return M

    self.progress_signal.emit(0, total, "Transforms", False)
    for a, b in zip(range(start, end), range(start + 1, end + 1)):
      if self.chk_align_inv.isChecked():
        warp_matrices[a] = get_transform(b, a)
      else:
        warp_matrices[b] = get_transform(a, b)
      self.progress_signal.emit(b, total, "Transforms", False)

    running_total_matrix = np.eye(3, 3, dtype=np.float64)

    sz = (node.height, node.width)
    if self.chk_align_inv.isChecked():
      offsets[end] = (0, 0, node.width, node.height)
      self.transforms[end] = (running_total_matrix[:2], (node.width,
                                                         node.height))
    else:
      offsets[start] = (0, 0, node.width, node.height)
      self.transforms[start] = (running_total_matrix[:2], (node.width,
                                                           node.height))

    self.progress_signal.emit(0, total, "Cumulative", False)

    if self.chk_align_inv.isChecked():
      a = start
      b = end
      c = -1
    else:
      a = start + 1
      b = end + 1
      c = 1

    for k, i in enumerate(range(a, b)[::c], 1):
      wm = np.copy(warp_matrices[i])

      tempwarp = np.vstack([wm, [0, 0, 1]])
      running_total_matrix = tempwarp.dot(running_total_matrix)

      warp_matrix = running_total_matrix[:2].astype(np.float64)
      c = np.vstack([warp_matrix, [0, 0, 1]])
      c_inv = np.linalg.inv(c)[:2]

      points = [[0, 0], [sz[1], 0], [0, sz[0]], [sz[1], sz[0]]]
      points = [c_inv.dot([p[0], p[1], 1]) for p in points]

      x_min = min([p[0] for p in points])
      x_max = max([p[0] for p in points])
      y_min = min([p[1] for p in points])
      y_max = max([p[1] for p in points])

      left_padding = x_min
      right_padding = x_max - sz[1]
      top_padding = y_min
      bottom_padding = y_max - sz[0]

      offsets[i] = (left_padding, top_padding, x_max, y_max)

      offset_trans = np.eye(3, 3, dtype=np.float64)
      offset_trans[0, 2] = left_padding
      offset_trans[1, 2] = top_padding
      new_warp_matrix = np.vstack([warp_matrix, [0, 0, 1]])

      new_warp_matrix = new_warp_matrix.dot(offset_trans)[:2]

      # (running matrix, (width, height))
      self.transforms[i] = (new_warp_matrix,
                            (int(sz[1] + right_padding - left_padding),
                             int(sz[0] + bottom_padding - top_padding)))

      self.progress_signal.emit(k, total, "Cumulative", False)

    left = math.floor(min([o[0] for o in offsets.values()]))
    top = math.floor(min([o[1] for o in offsets.values()]))
    right = math.ceil(max([o[2] for o in offsets.values()]))
    bottom = math.ceil(max([o[3] for o in offsets.values()]))

    self.width = right - left
    self.height = bottom - top

    self.offsets_xy = {
        o: (offsets[o][0] - left, offsets[o][1] - top)
        for o in offsets
    }

    data = [[f"{self.offsets_xy[i][0]:.8f}", f"{self.offsets_xy[i][1]:.8f}"]
            for i in sorted(self.offsets_xy.keys())]

    self.table_offsets.setModel(TableModel(data, ["x", "y"], True))

    self.progress.setFormat(None)

    self.align_start = start
    self.align_end = end
    self.align_mask_invert = alignmask_invert

    self.reset()

  def on_current_frame_changed(self, frame: Frame) -> None:
    frame = self.outputs.current.to_frame(
        self.main.current_output.to_time(frame))
    self.outputs.current.render_frame(frame, None, None,
                                      self.view.current_scene)

    start = self.start_n.value()
    row = frame - start
    model = self.table_offsets.model()
    if model == None:
      return
    if row >= 0 and row < model.rowCount(self.table_offsets):
      self.table_offsets.selectRow(row)
    else:
      self.table_offsets.clearSelection()

  def on_current_output_changed(self, cur, prev):
    self.start_n.setMaximum(
        self.main.current_output.prepared.original_clip.num_frames - 1)
    self.end_n.setMaximum(
        self.main.current_output.prepared.original_clip.num_frames - 1)
    self.on_current_frame_changed(self.main.current_output.last_showed_frame)

  def init_outputs(self) -> None:
    assert self.main.outputs
    self.outputs.clear()
