from __future__ import annotations

from PyQt6.QtWidgets import QWidget, QSizePolicy, QTableView
from PyQt6.QtCore import pyqtSlot, pyqtSignal
from vspreview.core import Frame, PushButton, VBoxLayout, HBoxLayout, SpinBox, ProgressBar, LineEdit, CheckBox
from vspreview.core.custom import ComboBox, TableModel
from vspreview.plugins import MappedNodesPlugin, PluginConfig, PluginGraphicsView
from vstools import vs

import math
import os
import cv2
import numpy as np
from PIL import Image

np.set_printoptions(suppress=True)
import local

import threading

core = vs.core

__all__ = ["UndermixPlugin"]

renderer = {
    "median": local.bilinear_median_bucket,
    "mean": local.bilinear_mean_bucket,
}

stitchmodes = [
    "Local features affine",
    "Local ECC translation",
    "Global features stitcher",
]

# feature matching
index_params = dict(
    algorithm=6,
    table_number=6,  # 12
    key_size=12,  # 20
    multi_probe_level=1)
search_params = dict(checks=50)
flann = cv2.FlannBasedMatcher(index_params, search_params)
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

number_of_iterations = 400
termination_eps = 1e-6
criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,
            number_of_iterations, termination_eps)


def feature_matching(cache, i1, i2):
  kp1, des1 = cache[i1]
  kp2, des2 = cache[i2]

  matches2to1 = flann.knnMatch(des2, des1, k=2)
  recip_matches = flann.knnMatch(des1, des2, k=2)

  matchesMask_ratio = [[0, 0] for i in range(len(matches2to1))]
  match_dict = {}
  for i, d in enumerate(matches2to1):
    if len(d) < 2: continue
    m, n = d

    if m.distance < 0.7 * n.distance:
      matchesMask_ratio[i] = [1, 0]
      match_dict[m.trainIdx] = m.queryIdx

  good = []
  matchesMask_ratio_recip = [[0, 0] for i in range(len(recip_matches))]

  for i, d in enumerate(recip_matches):
    if len(d) < 2: continue
    m, n = d
    if m.distance < 0.7 * n.distance:  # ratio
      if m.queryIdx in match_dict and match_dict[
          m.queryIdx] == m.trainIdx:  #reciprocal
        good.append(m)
        matchesMask_ratio_recip[i] = [1, 0]

  return ([kp1[m.queryIdx].pt
           for m in good], [kp2[m.trainIdx].pt for m in good])


class UndermixPlugin(MappedNodesPlugin, QWidget):
  _config = PluginConfig("moe.grass", "Undermix")

  progress_signal = pyqtSignal(int, int, str, bool)

  def setup_ui(self) -> None:
    self.view = PluginGraphicsView(self)

    self.start_n = SpinBox(minimum=0, maximum=100000)
    start_set = PushButton("Set", self, clicked=self.set_start)
    self.end_n = SpinBox(minimum=0, maximum=100000)
    end_set = PushButton("Set", self, clicked=self.set_end)

    self.start_n.setValue(0)
    self.end_n.setValue(100000)

    self.invert = CheckBox("Invert", checked=False)

    self.stitchmode = ComboBox()
    self.stitchmode.addItems(stitchmodes)
    self.stitchmode.setCurrentIndex(0)

    analyze = PushButton("Analyze", self, clicked=self.analyze)

    self.stitchmask = LineEdit("stitchmask.png")
    self.stitchmask.setSizePolicy(QSizePolicy.Policy.Preferred,
                                  QSizePolicy.Policy.Maximum)

    self.stitchmask_invert = CheckBox("Invert", checked=False)

    self.rendermask = LineEdit("rendermask.png")
    self.rendermask.setSizePolicy(QSizePolicy.Policy.Preferred,
                                  QSizePolicy.Policy.Maximum)

    self.rendermask_invert = CheckBox("Invert", checked=False)

    self.outpath = LineEdit("stitched.png")
    self.outpath.setSizePolicy(QSizePolicy.Policy.Preferred,
                               QSizePolicy.Policy.Maximum)

    self.rendermode = ComboBox()
    self.rendermode.addItems(renderer.keys())
    self.rendermode.setCurrentIndex(0)
    render = PushButton("Render", self, clicked=self.render)

    self.progress = ProgressBar()
    self.progress.setTextVisible(True)

    self.progress_signal.connect(self.update_progress)

    self.table_offsets = QTableView(None)
    self.table_offsets.setModel(TableModel([], ["x", "y"], True))
    self.table_offsets.setSizePolicy(QSizePolicy.Policy.Minimum,
                                     QSizePolicy.Policy.Preferred)

    hbox1 = HBoxLayout(
        None, [self.start_n, start_set, self.end_n, end_set, self.invert])
    hbox2 = HBoxLayout(None, [
        self.stitchmask, self.stitchmask_invert, self.rendermask,
        self.rendermask_invert
    ])
    hbox3 = HBoxLayout(None, [self.stitchmode, analyze])
    hbox4 = HBoxLayout(None, [self.outpath, self.rendermode, render])

    vbox = VBoxLayout(None, [self.table_offsets, hbox1, hbox2, hbox3, hbox4])

    hbox3 = HBoxLayout(None, [vbox, self.view])
    VBoxLayout(self, [hbox3, self.progress])

    self.features = {}
    self.transforms = {}
    self.offsets_xy = {}
    self.width = None
    self.height = None
    self.with_mask = False

  def set_start(self):
    self.start_n.setValue(self.main.current_output.last_showed_frame)

  def set_end(self):
    self.end_n.setValue(self.main.current_output.last_showed_frame)

  def render(self):
    self.analyze()
    node = self.main.current_output.prepared.original_clip
    node = core.resize.Point(node, format=vs.RGB24)

    rendermode = self.rendermode.currentIndex()
    start = self.start_n.value()
    end = self.end_n.value()
    total = end - start
    output_filename = self.outpath.text() or "stitched.png"

    rotated_images = {}

    self.progress_signal.emit(0, total, "Rotating frames", False)

    for i in range(start, end + 1):
      (warp_matrix, size) = self.transforms[i]
      frame = node.get_frame(i)

      im = np.ctypeslib.as_array(frame).swapaxes(0, 2).swapaxes(0, 1)

      im = im.reshape((node.height, node.width, 3))
      im = cv2.cvtColor(im, cv2.COLOR_RGB2RGBA)

      mask_im = np.ones(im.shape[:2], dtype=np.uint8)
      mask_im[:] = 255

      feather_im = np.ones(im.shape[:2], dtype=np.float64)

      xd = feather_im.shape[0] // 8
      yd = feather_im.shape[1] // 8

      for x in range(xd):
        feather_im[x, :] = x / xd
        feather_im[-x, :] = x / xd

      for y in range(yd):
        feather_im[:, y] *= y / yd
        feather_im[:, -y] *= y / yd

      im = cv2.warpAffine(im,
                          warp_matrix,
                          size,
                          flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP,
                          borderMode=cv2.BORDER_REPLICATE).astype(np.float64)

      mask = cv2.warpAffine(mask_im,
                            warp_matrix,
                            size,
                            flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP,
                            borderMode=cv2.BORDER_CONSTANT,
                            borderValue=0).astype(np.float64)

      feather_im = cv2.warpAffine(feather_im,
                                  warp_matrix,
                                  size,
                                  flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP,
                                  borderMode=cv2.BORDER_CONSTANT,
                                  borderValue=0).astype(np.float64)

      im[:, :, 3] = mask
      im = np.dstack([im, feather_im])
      rotated_images[i] = im

      self.progress_signal.emit(i - start, total, "Rotating frames", False)

    offsets_xy = [self.offsets_xy[k] for k in rotated_images]
    rotated_images = list(rotated_images.values())

    if self.invert.isChecked():
      rotated_images.reverse()
      offsets_xy.reverse()

    offsets_xy = np.array(offsets_xy, dtype=np.float64)

    self.progress_signal.emit(0, self.height, "Rendering", False)

    def render(rendermode, rotated_images, offsets_xy, width, height, path):
      im = list(renderer.values())[rendermode](
          rotated_images, offsets_xy,
          width, height, lambda c: self.progress_signal.emit(
              c + 1, height, "Rendering", False))
      path2 = path
      n = 1
      while os.path.exists(path2):
        a, b = os.path.splitext(path)
        path2 = f"{a}{n}{b}"
        n += 1

      self.progress_signal.emit(height, height, "Saving", False)
      Image.fromarray(im.astype(np.uint8)).save(path2)
      self.progress_signal.emit(height, height, f"Saved as {path2}", True)

    t = threading.Thread(target=render,
                         args=[
                             rendermode, rotated_images, offsets_xy,
                             self.width, self.height, output_filename
                         ],
                         daemon=True)

    t.start()

  @pyqtSlot(int, int, str, bool)
  def update_progress(self, c, total, text, r):
    self.progress.setValue(c)
    self.progress.setMaximum(total)
    if r:
      self.progress.setFormat(text)
    else:
      self.progress.setFormat(f"{text}: {c}/{total}")

  def get_mask(self, mask, n):
    if mask is None or n not in self.transforms: return None

    warp_matrix = self.transforms[n][0]

    warp_matrix = np.vstack([warp_matrix, [0, 0, 1]])
    warp_matrix = np.linalg.inv(warp_matrix)[:2]

    warp_matrix = np.vstack([warp_matrix, [0, 0, 1]])
    trans = np.eye(3, dtype=np.float64)
    trans[0, 2] = self.offsets_xy[n][0]
    trans[1, 2] = self.offsets_xy[n][1]
    warp_matrix = warp_matrix.dot(trans)[:2]

    return cv2.warpAffine(mask,
                          warp_matrix, (1920, 1080),
                          flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP,
                          borderMode=cv2.BORDER_CONSTANT).astype(np.uint8)

  def get_features(self, f, n, mask=None):
    if n in self.features:
      return self.features[n]
    orb = cv2.ORB_create(1000)
    gray = np.ctypeslib.as_array(f).reshape((1080, 1920))
    self.features[n] = orb.detectAndCompute(gray, mask)
    return self.features[n]

  def get_stitchmask(self):
    if not os.path.exists(self.stitchmask.text() or "stitchmask.png"):
      return None

    stitchmask = Image.open(self.stitchmask.text() or "stitchmask.png")
    stitchmask = stitchmask.convert(mode="L")
    stitchmask = np.array(stitchmask).astype(np.uint8)

    if self.stitchmask_invert.isChecked():
      stitchmask = 255 - stitchmask

    return stitchmask

  def get_node(self, node):
    if node.format.id == vs.GRAY32: return node

    if self.width == None: return node

    stitchmask = self.get_stitchmask()

    def points(n, f):
      im = np.ctypeslib.asarray(f[0]).swapaxes(0, 2).swapaxes(0, 1)

      kp, des = self.get_features(f[1], n, stitchmask)
      im = cv2.drawKeypoints(im, kp, None, color=(255, 0, 0), flags=0)

      f = f[0].copy()
      np.copyto(np.asarray(f[0]), im[:, :, 0])
      np.copyto(np.asarray(f[1]), im[:, :, 1])
      np.copyto(np.asarray(f[2]), im[:, :, 2])
      return f

    node = core.resize.Bicubic(node, format=vs.RGB24, matrix_in_s="709")

    if self.width == None and self.stitchmode.currentIndex() == 0:
      gray = core.resize.Bicubic(node, format=vs.GRAY8, matrix_s="709")
      gray = core.std.RemoveFrameProps(gray, "_Matrix")
      gray = core.std.Sobel(gray)

      node = core.std.ModifyFrame(clips=[node, gray],
                                  clip=node,
                                  selector=points)
      return node

    resized = core.resize.Bicubic(node, width=self.width, height=self.height)

    def rotate(n, f):
      if n not in self.transforms or n not in self.offsets_xy:
        return f[1]

      im = np.ctypeslib.asarray(f[0]).swapaxes(0, 2).swapaxes(0, 1)

      if self.stitchmode.currentIndex() == 0 and n in self.features:
        kp, _ = self.features[n]
        im = cv2.drawKeypoints(im, kp, None, color=(255, 0, 0), flags=0)

      (warp_matrix, size) = self.transforms[n]

      im = cv2.warpAffine(im,
                          warp_matrix,
                          size,
                          flags=cv2.INTER_CUBIC + cv2.WARP_INVERSE_MAP,
                          borderMode=cv2.BORDER_CONSTANT).astype(np.uint8)

      im2 = np.zeros((f[1].height, f[1].width, 3), np.uint8)

      x, y = self.offsets_xy[n]

      x = int(round(x))
      y = int(round(y))
      x2 = x + im.shape[1]
      y2 = y + im.shape[0]

      x = max(x, 0)
      y = max(y, 0)
      x2 = min(x2, f[1].width)
      y2 = min(y2, f[1].height)

      im2[y:y2, x:x2] = im[:y2 - y, :x2 - x]

      f = f[1].copy()
      np.copyto(np.asarray(f[0]), im2[:, :, 0])
      np.copyto(np.asarray(f[1]), im2[:, :, 1])
      np.copyto(np.asarray(f[2]), im2[:, :, 2])
      return f

    resized = core.std.BlankClip(resized)
    node = core.std.ModifyFrame(clips=[node, resized],
                                clip=resized,
                                selector=rotate)

    def withmask(n, f):
      im = np.ctypeslib.asarray(f[1]).swapaxes(0, 2).swapaxes(0, 1)
      im0 = np.ctypeslib.asarray(f[0]).swapaxes(0, 2).swapaxes(0, 1)
      im[0:im0.shape[0], 0:im0.shape[1], :] = im0

      mask = self.get_mask(stitchmask, n)
      if mask is not None:
        im[0:1080, im0.shape[1]:im0.shape[1] + 1920, 0] = mask
        im[0:1080, im0.shape[1]:im0.shape[1] + 1920, 1] = mask
        im[0:1080, im0.shape[1]:im0.shape[1] + 1920, 2] = mask

        f = f[1].copy()
        np.copyto(np.asarray(f[0]), im[:, :, 0])
        np.copyto(np.asarray(f[1]), im[:, :, 1])
        np.copyto(np.asarray(f[2]), im[:, :, 2])
        return f

      return f[1]

    resized = core.std.BlankClip(resized, width=int(resized.width * 2))

    node = core.std.ModifyFrame(clips=[node, resized],
                                clip=resized,
                                selector=withmask)

    return node

  def analyze2(self):
    node = self.main.current_output.prepared.original_clip

    gray = core.resize.Bicubic(node, format=vs.GRAY8, matrix_s="709")
    gray = core.std.RemoveFrameProps(gray, "_Matrix")
    gray = core.std.Sobel(gray)

    finder = cv.ORB.create()

    match_conf = 0.3
    matcher = cv2.detail_AffineBestOf2NearestMatcher(False, True, match_conf)

    estimator = cv2.detail_AffineBasedEstimator()

  def analyze(self):
    self.features.clear()
    node = self.main.current_output.prepared.original_clip

    gray = core.resize.Bicubic(node, format=vs.GRAY8, matrix_s="709")
    gray = core.std.RemoveFrameProps(gray, "_Matrix")
    gray = core.std.Sobel(gray)

    features = {}
    warp_matrices = {}
    offsets = {}

    start = self.start_n.value()
    end = self.end_n.value()
    total = end - start

    if end <= start: return

    stitchmask = None
    if self.transforms and not self.with_mask:
      stitchmask = self.get_stitchmask()

    def get_transform(i1, i2):
      if self.stitchmode.currentIndex() == 1:
        im1 = np.ctypeslib.as_array(gray.get_frame(i1)).reshape((1080, 1920))
        im2 = np.ctypeslib.as_array(gray.get_frame(i2)).reshape((1080, 1920))
        (cc, M) = cv2.findTransformECC(im1, im2, np.eye(2, 3,
                                                        dtype=np.float32),
                                       cv2.MOTION_TRANSLATION, criteria, None)
        # TODO: stitchmask
        return M

      mask1 = self.get_mask(stitchmask, i1)
      mask2 = self.get_mask(stitchmask, i2)

      if mask1 is not None and mask2 is not None:
        self.with_mask = True
      else:
        mask1 = None
        mask2 = None
        self.with_mask = False

      self.get_features(gray.get_frame(i1), i1, mask1)
      self.get_features(gray.get_frame(i2), i2, mask2)

      pts1, pts2 = feature_matching(self.features, i1, i2)

      src_pts = np.float32(pts1).reshape(-1, 1, 2)
      dst_pts = np.float32(pts2).reshape(-1, 1, 2)

      M, mask = cv2.estimateAffinePartial2D(src_pts,
                                            dst_pts,
                                            cv2.USAC_MAGSAC,
                                            ransacReprojThreshold=5.0)

      return M

    self.progress_signal.emit(0, total, "Transforms", False)
    for a, b in zip(range(start, end), range(start + 1, end + 1)):
      if self.invert.isChecked():
        warp_matrices[a] = get_transform(b, a)
      else:
        warp_matrices[b] = get_transform(a, b)
      self.progress_signal.emit(b, total, "Transforms", False)

    running_total_matrix = np.eye(3, 3, dtype=np.float64)

    sz = (node.height, node.width)
    if self.invert.isChecked():
      offsets[end] = (0, 0, node.width, node.height)
      self.transforms[end] = (running_total_matrix[:2], (node.width,
                                                         node.height))
    else:
      offsets[start] = (0, 0, node.width, node.height)
      self.transforms[start] = (running_total_matrix[:2], (node.width,
                                                           node.height))

    self.progress_signal.emit(0, total, "Cumulative", False)

    if self.invert.isChecked():
      a = start
      b = end
      c = -1
    else:
      a = start + 1
      b = end + 1
      c = 1

    for k, i in enumerate(range(a, b)[::c], 1):
      wm = np.copy(warp_matrices[i])

      tempwarp = np.vstack([wm, [0, 0, 1]])
      running_total_matrix = tempwarp.dot(running_total_matrix)

      warp_matrix = running_total_matrix[:2].astype(np.float64)
      c = np.vstack([warp_matrix, [0, 0, 1]])
      c_inv = np.linalg.inv(c)[:2]

      points = [[0, 0], [sz[1], 0], [0, sz[0]], [sz[1], sz[0]]]
      points = [c_inv.dot([p[0], p[1], 1]) for p in points]

      x_min = min([p[0] for p in points])
      x_max = max([p[0] for p in points])
      y_min = min([p[1] for p in points])
      y_max = max([p[1] for p in points])

      left_padding = x_min
      right_padding = x_max - sz[1]
      top_padding = y_min
      bottom_padding = y_max - sz[0]

      offsets[i] = (left_padding, top_padding, x_max, y_max)

      offset_trans = np.eye(3, 3, dtype=np.float64)
      offset_trans[0, 2] = left_padding
      offset_trans[1, 2] = top_padding
      new_warp_matrix = np.vstack([warp_matrix, [0, 0, 1]])

      new_warp_matrix = new_warp_matrix.dot(offset_trans)[:2]

      # (running matrix, (width, height))
      self.transforms[i] = (new_warp_matrix,
                            (int(sz[1] + right_padding - left_padding),
                             int(sz[0] + bottom_padding - top_padding)))

      self.progress_signal.emit(k, total, "Cumulative", False)

    left = math.floor(min([o[0] for o in offsets.values()]))
    top = math.floor(min([o[1] for o in offsets.values()]))
    right = math.ceil(max([o[2] for o in offsets.values()]))
    bottom = math.ceil(max([o[3] for o in offsets.values()]))

    self.width = right - left
    self.height = bottom - top

    self.offsets_xy = {
        o: (offsets[o][0] - left, offsets[o][1] - top)
        for o in offsets
    }

    data = [[f"{self.offsets_xy[i][0]:.8f}", f"{self.offsets_xy[i][1]:.8f}"]
            for i in sorted(self.offsets_xy.keys())]

    self.table_offsets.setModel(TableModel(data, ["x", "y"], True))

    self.progress.setFormat(None)

    self.reset()

  def on_current_frame_changed(self, frame: Frame) -> None:
    frame = self.outputs.current.to_frame(
        self.main.current_output.to_time(frame))
    self.outputs.current.render_frame(frame, None, None,
                                      self.view.current_scene)

    start = self.start_n.value()
    row = frame - start
    model = self.table_offsets.model()
    if model == None:
      return
    if row >= 0 and row < model.rowCount(self.table_offsets):
      self.table_offsets.selectRow(row)
    else:
      self.table_offsets.clearSelection()

  def on_current_output_changed(self, cur, prev):
    self.features.clear()
    self.offsets_xy.clear()
    self.transforms.clear()
    self.width = None
    self.height = None
    self.start_n.setMaximum(
        self.main.current_output.prepared.original_clip.num_frames - 1)
    self.end_n.setMaximum(
        self.main.current_output.prepared.original_clip.num_frames - 1)
    self.on_current_frame_changed(self.main.current_output.last_showed_frame)

  def init_outputs(self) -> None:
    assert self.main.outputs
    self.outputs.clear()
